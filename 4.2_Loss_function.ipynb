{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e1866d1",
   "metadata": {},
   "source": [
    "신경망 학습에서는 현재의 상태를 \"하나의 지표\"로 표현한다. 그리고 그 지표를 가장 좋게 만들어주는 가중치 매개변수의 값을 탐색하는 것이다. 신경망은 \"하나의 지표\"를 기준으로 최적의 매개변수 값을 탐색한다. 신경망 함수에서 사용하는 지표는 \"손실 함수(Loss Function)\"라고 한다. 이 손실 함수는 임의의 함수를 사용할 수도 있지만 일반적으로는 오차제곱합과 교차 엔트로피 오차를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e538db",
   "metadata": {},
   "source": [
    "# 4.2.1 오차제곱합(Sum of Squares for Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbf5f1d",
   "metadata": {},
   "source": [
    "가장 많이 쓰이는 손실 함수는 \"오차제곱합(Sum of Squares for Error, SSE)\"이다. 수식으로는 다음과 같다.\n",
    "\n",
    "$\n",
    "E = \n",
    "\\frac{1}{2}\\sum_{k} (y_k - t_k)^2\n",
    "\\qquad$ [식 4.1]\n",
    "\n",
    "여기서 $y_k$는 신경망의 출력(신경망이 추정한 값), $t_k$는 정답 레이블, $k$는 데이터의 차원 수를 나타낸다.<br>\n",
    "앞서서 한 \"손글씨 숫자 인식\"의 예에서는 $y_k 와 t_k$는 각각\n",
    "\n",
    "$\n",
    "y_k = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0] \\\\\n",
    "t_k = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "$\n",
    "\n",
    "가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a489f0e",
   "metadata": {},
   "source": [
    "이 배열들의 원소는 첫 번째 인덱스부터 순서대로 숫자 \"0\", \"1\", \"2\", ...일 때의 값이다. 여기서 출력 $y$는 소프트맥스 함수의 출력 값이다. 소프트맥스의 함수의 출력 값은 확률로 해석할 수 있으므로, 이 예에서는 이미지가 \"0\"일 확률은 \"0.1(10%)\", \"1\"일 확률은 \"0.05(5%)\", \"2\"일 확률은 \"0.6(60%)\"가 된다. 이는 정답 레이블이 실제 숫자는 \"2\"임을 알려준다. 위의 $t_k$처럼 한 원소만 1로 하고 그 외는 0으로 나타내는 표기법을 원-핫-인코딩이라고 한다.<br>\n",
    "이 오차제곱합을 파이썬으로 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4417f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sum_squares_error(y, t):\n",
    "    sse = 0.5 * np.sum((y-t)**2)\n",
    "    \n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0d4f365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09750000000000003\n",
      "0.5975\n"
     ]
    }
   ],
   "source": [
    "# 정답 레이블\n",
    "t_k = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# ex1) 숫자 \"2\"일 확률이 가장 높다고 판단한 경우\n",
    "y_k = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "print(sum_squares_error(np.array(y_k), np.array(t_k)))\n",
    "\n",
    "# ex2) 숫자 \"7\"일 확률이 가장 높다고 판단한 경우\n",
    "y_k = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "print(sum_squares_error(np.array(y_k), np.array(t_k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0b09d9",
   "metadata": {},
   "source": [
    "첫 번째 예는 정답이 \"2\"이고, 신경망의 출력도 \"2\"에서 가장 높은 경우이다. 두 번째 예에서는 정답은 똑같이 \"2\"이지만, 신경망의 출력은 \"7\"에서 가장 높다. 따라서 각 오차제곱합의 값을 비교하면 정답을 맞춘 첫 번재 경우에 더 작고, 더 정답에 가까울 것으로 추측된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c741af",
   "metadata": {},
   "source": [
    "# 4.2.2 교차 엔트로피 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d31ac2",
   "metadata": {},
   "source": [
    "또 다른 손실 함수로서 \"교차 엔트로피 오차(Cross Entropy Error, CEE)\"도 자주 이용한다. 교차 엔트로피 오차의 수식은 다음과 같다.\n",
    "\n",
    "$\n",
    "E = \n",
    "-\\sum_{k} t_k\\ln y_k\n",
    "\\qquad$ [식 4.2]\n",
    "\n",
    "마찬가지로 $y_k$는 신경망의 출력값, $t_k$는 정답 레이블이다. 그리고 $t_k$는 원-핫-인코딩이 되어 있다. 따라서 실제로는 수식에서 정답의 출력값만을 자연로그로 계산하게 된다. 예를 들어, 정답 레이블이 \"2\"에서 1이고, 이 때의 출력값이 0.6이라면, 교차 엔트로피 오차는 $-\\ln {0.6} = 0.51$이 된다. 같은 조건에서 신경망 출력이 0.1이라면 오차는 $-\\ln {0.1} = 2.30$이 된다.\n",
    "\n",
    "밑에 자연로그의 그래프를 그려두었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20af1d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.01, 1, 0.01)\n",
    "y = np.log(x)\n",
    "\n",
    "plt.plot(x, y, label=\"$y = \\ln x$\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.ylim(-5.0, 0.0)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b6b30",
   "metadata": {},
   "source": [
    "이 그림에서 보이듯이 $x$가 1일 때 $y$는 0이 되고, $x$가 0에 가까워질 수록, $y$의 값은 작아진다. 한마디로 오차가 커진다.<br>\n",
    "이를 구현해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f44201b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7    ## delta는 y = 0일 때를 대비하여 작은 값을 넣어준다.\n",
    "    cee = -np.sum(t*np.log(y+delta))\n",
    "\n",
    "    return cee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e95a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510825457099338\n",
      "2.3025840929945454\n"
     ]
    }
   ],
   "source": [
    "# 정답 레이블\n",
    "t_k = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# ex1) 숫자 \"2\"일 확률이 가장 높다고 판단한 경우\n",
    "y_k = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "print(cross_entropy_error(np.array(y_k), np.array(t_k)))\n",
    "\n",
    "# ex2) 숫자 \"7\"일 확률이 가장 높다고 판단한 경우\n",
    "y_k = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "print(cross_entropy_error(np.array(y_k), np.array(t_k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9692c3",
   "metadata": {},
   "source": [
    "이는 앞서 구한 오차제곱합의 판단과 일치한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee3d6f9",
   "metadata": {},
   "source": [
    "# 4.2.3 미니배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c962feef",
   "metadata": {},
   "source": [
    "앞서서 까지는 하나의 훈련 데이터에 관한 손실 함수만을 생각하였으니, 모든 훈련 데이터에 관한 손실 함수를 구하는 방법을 생각해보자. 예를 들어, 교차 엔트로피 오차의 경우는 [식 4.3]과 같이 된다.\n",
    "\n",
    "$\n",
    "E = \n",
    "-\\frac{1}{N} \\sum_{n} \\sum_{k} t_nk\\ln y_nk\n",
    "\\qquad$ [식 4.3]\n",
    "\n",
    "이때 데이터가 N개 라면 $t_nk$는 n번째 데이터의 k번째 값을 의미한다. 복잡해 보이지만, 그저 각 데이터의 손실 함수의 평균을 구하는 것 뿐이다. 그런데 MNIST의 데이터셋은 훈련 데이터가 60,000개가 있었다. 그래서 모든 데이터를 대상으로 손실 함수의 합을 구하려면 시간이 좀 걸린다. 더 나아가 빅데이터 수준이 되면 그 수는 수백만에서 수천만도 넘는 거대한 값이 되기도 한다. 이 많은 데이터를 대상으로 일일이 손실 함수를 계산하는 것은 현실적이지 않다. 이런 경우 데이터 일부를 추려 전체의 \"근사치\"로 이용할 수 있다. 신경망 학습에서도 훈련 데이터로부터 일부만 골라 학습을 수행한다. 이 일부를 \"미니배치(mini-batch)\"라고 한다. 가령 60,000장의 훈련 데이터 중에서 100장을 무작위로 뽑아 그 100장만을 사용하여 학습하는 것이다.<br>\n",
    "이제 부터 미니배치 학습을 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7d1e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from source.dataset.mnist import load_mnist\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a436f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0] ## 60,000\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5c68ef",
   "metadata": {},
   "source": [
    "이렇게 하면 60,000장의 데이터셋 중에서 10장의 데이터를 무작위로 빼내올 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e78209",
   "metadata": {},
   "source": [
    "# 4.2.4 교차 엔트로피 오차 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bf60d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:    ## 데이터가 하나인 경우\n",
    "        y = y.reshape(1, y.size)\n",
    "        batch_size = y.shape[0]\n",
    "        \n",
    "        if t.ndim == 1:    ## one_hot_label=False 인 경우\n",
    "            t = t.reshape(1, t.size)\n",
    "            cee = -np.sum(np.log(y[np.arange(batch_size), t]+1e-7)) / batch_size\n",
    "    \n",
    "        else:\n",
    "            t = t.reshape(1, t.size)\n",
    "            cee = -np.sum(t*np.log(y+1e-7)) / batch_size\n",
    "            \n",
    "    return cee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7540cd06",
   "metadata": {},
   "source": [
    "# 4.2.5 왜 손실 함수를 설정하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a8030",
   "metadata": {},
   "source": [
    "왜 굳이 손실 함수를 사용해야 하는 걸까?\n",
    "\n",
    "예컨대 숫자 인식의 경우도 우리의 궁극적인 목적은 높은 \"정확도\"를 끌어내는 매개변수 값을 찾아내는 것이었다. 그렇다면 \"정확도\"라는 지표를 놔두고 \"손실 함수의 값\"이라는 우회적인 방법을 택하는 이유는 무엇일까?\n",
    "\n",
    "이 의문은 신경망 학습에서의 \"미분\"의 역할에 주목한다면 해결된다. 신경망 학습에서는 최적의 매개변수(가중치와 편향)를 탐색할 때 손실 함수의 값을 가능한 한 작게 하는 매개변수 값을 찾는다. 이때 매개변수의 미분을 계산하고, 그 미분 값을 단서로 매개변수의 값을 서서히 갱신하는 과정을 반복한다.\n",
    "\n",
    "가령 여기에 가상의 신경망이 있고 그 신경망의 어느 한 가중치 매개변수에 주목한다고 하자. 이때 그 가중치 매개변수의 손실 함수의 미분이란, \"가중치 매개변수의값을 아주 조금 변화시켰을 때, 손실 함수가 어떻게 변하나\"라는 의미이다. 만약 이 미분 값이 음수면 그 가중치 매개변수를 양의 방향으로 변화시켜 손실 함수의 값을 줄일 수 있다. 반대의 경우에는 양의 방향으로 움직여 손실 함수의 값을 줄인다. 그리고 미분 값이 0일 경우에는 갱신을 종료한다.\n",
    "\n",
    "정화도를 지표로 삼어서는 안 되는 이유는 미분 값이 대부분의 장소에서 0이 되어 매개변수를 갱신할 수 없기 때문이다. \n",
    "정리하자면,\n",
    "### 신경망을 학습할 때 정확도를 지표로 삼어서는 안 된다. 정확도를 지표로 하면 매개변수의 미분이 대부분의 장소에서 0이 되기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330ce478",
   "metadata": {},
   "source": [
    "정확도를 지표로 삼으면 매개변수의 미분이 대부분의 장소에서 0이 되는 이유는 무엇일까? 구체적인 예를 들어보자.\n",
    "\n",
    "한 신경망이 100장의 훈련 데이터 중 32장을 올바르게 인식한다고 하자. 그렇다면 정확도는 32%이다. 만약 정확도가 지표였다면 가중치 매개변수의 값을 조금 바꾼다고 해도 정확도는 그대로 32%일 것이다. 즉 매개변수를 약간만 조정해서는 정확도가 개선되지 않고 일정하게 유지된다. 혹여나 정확도가 개선되더라도 그 값은 불연속적인 띄엄띄엄한 값으로 변화한다.\n",
    "\n",
    "이는 활성화 함수로서 계단 함수가 아닌 시그모이드 함수를 사용하는 이유와 일치한다.<br>\n",
    "<img src=images/4_04.png height=200px width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25148a4e",
   "metadata": {},
   "source": [
    "시그모이드 함수는 어느 장소더라도 미분 값이 0이 되지 않는다. 이는 신경망 학습에서 중요한 성질으로, 기울기가 0이 되지 않는 덕분에 신경망이 올바르게 학습할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
