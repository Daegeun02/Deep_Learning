{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76ab5af7",
   "metadata": {},
   "source": [
    "신경망 학습의 순서를 확인해보자.\n",
    "#### 전제 \n",
    "신경망에는 적응 가능한 가중치와 편향이 있고, 이 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을 \"학습\"이라고 한다. 신경망 학습은 다음과 같이 4단계로 수행한다.\n",
    "#### 1단계 - 미니배치\n",
    "훈련 데이터 중 일부를 무작위로 가져온다. 이렇게 선별한 데이터를 미니배치라 하며, 그 미니배치의 손실 함수 값을 줄이는 것을 목표로 한다.\n",
    "#### 2단계 - 기울기 산출\n",
    "미니배치의 손실 함수 값을 줄이기 위해  각 가중치 매개변수의 기울기 값을 계산한다. 기울기는 손실 함수의 값을 가장 작게하는 방향을 제시한다.\n",
    "#### 3단계 - 매개변수 갱신\n",
    "가중치 매개변수를 기울기 방향으로 아주 조금 갱신한다.\n",
    "#### 4단계 - 반복\n",
    "1~3 단계를 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071bf6d",
   "metadata": {},
   "source": [
    "이는 경사 하강법으로 매개변수를 갱신하는 방법이다. 이때 데이터를 미니배치로 무작위로 선정하기 때문에 \"__확률적 경사 하강법(stochastic gradient descent)__\"라고 부른다. 딥러닝 프레임워크는 이를 \"__SGD__\"라는 함수로 이 기능을 구현하고 있다.<br>\n",
    "이제부터 MNIST 데이터셋을 사용하여 학습을 수행하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b37977",
   "metadata": {},
   "source": [
    "# 4.5.1 2층 신경망 클래스 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8608d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from functions import Function\n",
    "\n",
    "F = Function()\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params[\"W1\"] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params[\"W2\"] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params[\"b1\"] = np.zeros(hidden_size)\n",
    "        self.params[\"b2\"] = np.zeros(output_size)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \n",
    "        W1, W2 = self.params[\"W1\"], self.params[\"W2\"]\n",
    "        b1, b2 = self.params[\"b1\"], self.params[\"b2\"]\n",
    "        \n",
    "        a1 = x@W1 + b1\n",
    "        z1 = F.sigmoid(a1)\n",
    "        a2 = z1@W2 + b2\n",
    "        y = F.softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    # x: 입력 데이터, t: 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        loss = F.cross_entropy_error(y, t)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def accuracy(y, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grd = {}\n",
    "        grd[\"W1\"] = F.numerical_gradient(loss_W, self.params[\"W1\"])\n",
    "        grd[\"W2\"] = F.numerical_gradient(loss_W, self.params[\"W2\"])\n",
    "        grd[\"b1\"] = F.numerical_gradient(loss_W, self.params[\"b1\"])\n",
    "        grd[\"b2\"] = F.numerical_gradient(loss_W, self.params[\"b2\"])\n",
    "        \n",
    "        return grd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b70d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100, 10)\n",
      "(100,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
    "print(net.params[\"W1\"].shape)\n",
    "print(net.params[\"W2\"].shape)\n",
    "print(net.params[\"b1\"].shape)\n",
    "print(net.params[\"b2\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247d5aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "y = net.predict(x)\n",
    "print(y.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b6f35fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100, 10)\n",
      "(100,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "t = np.random.randn(100, 10)\n",
    "\n",
    "grd = net.numerical_gradient(x, t)\n",
    "\n",
    "print(grd[\"W1\"].shape)\n",
    "print(grd[\"W2\"].shape)\n",
    "print(grd[\"b1\"].shape)\n",
    "print(grd[\"b2\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff12b582",
   "metadata": {},
   "source": [
    "우선 init 메소드는 클래스를 초기화 해준다. 받아들이는 인수는 순서대로 \n",
    "1. input_size: 입력층 뉴런 수 \n",
    "2. hidden_size: 은닉층 뉴런 수 \n",
    "3. output_size: 출력층 뉴런 수 \n",
    "\n",
    "이다.\n",
    "예를 들어, 손글씨 숫자 인식에서는 크기가 $28 \\times 28$인 입력 이미지가 총 784개 이고, 출력은 10개가 된다. 따라서 input_size=784, output_size=10이 되고, hidden_size는 적절히 선택해 주면 된다.<br>\n",
    "이 초기화 메소드에서는 가중치 매개변수도 초기화한다. 가중치 매개변수의 초깃값을 무엇으로 설정하냐가 신경망 학습의 성공을 좌우하기도 한다. 지금은 매개변수는 정규분포를 따르는 난수로 정의하고, 편향은 0으로 하였다. predict(self, x)와 accuracy(self, x, t) 메소드는 앞에서 다룬 간단한 함수이다. loss(self, x, t) 메소드는 손실 함수의 값을 계산하도록 하는 메소드이다. 손실 함수는 cross_entropy_error 함수를 이용해 계산한다. 마지막 numerical_gradient(self, x, t) 메소드는 각 매개변수의 기울기를 계산한다. 수치미분 방식으로 각 매개변수의 손실 함수에 대한 기울기를 계산한다. 마지막 gradient(self, x, t)는 다음 장에서 구현할 메소드이다. 이 메소드는 오차역전파법을 사용하여 기울기를 효율적이고 빠르게 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6901e8",
   "metadata": {},
   "source": [
    "# 4.5.2 미니배치 학습 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781156dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from source.dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "# hyper parameter\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    \n",
    "    # 기울기 계산\n",
    "    grd = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grd = network.gradient(x_batch, t_batch) => 성능 개선판\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in [\"W1\", \"W2\", \"b1\", \"b2\"]:\n",
    "        network.params[key] -= learning_rate * grd[key]\n",
    "        \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b10916ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAFNCAYAAACAH1JNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfUElEQVR4nO3df5RddXnv8fdjSIyS8BsCJGhAoy1g+WH44VJj1gURIgpeXFdoxQDVlHvFq/VnNFZvW61I7r2olQq0WskVRJdgS72pKJa5QBUFIokiIjGFMhAEgkBCREh47h97px6Gk8mZzDlnz3fm/VrrrDl7f7977+dMmIfP7L3PnMhMJEmSVI7nNF2AJEmSRsYAJ0mSVBgDnCRJUmEMcJIkSYUxwEmSJBXGACdJklQYA9w4FhF3RcSxfTrWhRHxZ9u57T9HxMJu1zTCGjZExAFN1iBp6+xnI6rBfjYBGODUFZl5dmb+5XZue0JmXgIQEWdExA3dre6ZImIgIt4+pIZpmbmmB8c6JyJujojfRsSX24wfExE/j4iNEXFtRLywZSwi4tMRsa5+nBcR0TI+u95mY72PY4fs+w8j4u6IeDwi/iEiduv265PGI/vZVo/VWD/TsxngNK5ExA5N1zDEfcAngC8NHYiIPYArgT8DdgNuBr7WMmURcDJwCPAHwInAn7SMfxX4MbA7sAT4RkTsWe/7IOAi4HRgBrAR+JvuvSxJvWY/q/qZtiIzfYzTB3AXcGz9/LnAZ6h+AO+rnz+3HtsD+BbwCPAwcD3wnHrsQ8C9wHrgDuCYrRzry8An6ufzgUHgfcADwFrgzGHqHADeDvw+8ASwGdgAPNJS+/8E/h34FXAh8Lwhx/oQcD/wf4Bd69fzIPDr+vmsev4n6/0/UR/j8/X6BF5cP98ZWFZvfzfw0ZbvxxnADXU9vwb+DTihg3+LTwBfHrJuEfD9luUdgd8Av1cvfx9Y1DL+x8CN9fOXAL8FpreMXw+cXT//K+CylrEXAU+2zvfho6SH/Wzi9jMf7R+egZs4lgBHA4dS/QZ0JNUPMlSNaRDYk+pszUeAjIiXAucAR2TmdOB1VE20E3tTNY6ZVD+oF0TErsNtkJm3A2cDP8jqEsAu9dCnqX7ADwVeXO/zY0OOtRvwQqom8hzg7+vlF1A1kc/Xx1hC1RjOqY9xTptS/rqu/QDgNcDbgDNbxo+iav57AOcBX2y9FDACBwErW17/48Av6/XPGq+ft46tycz1w4y37vuXVAHuJdtRpzTW2M+YUP1MbRjgJo4/Av4iMx/IzAeBP6e6vAbwFLAP8MLMfCozr8/qV6DNVL8tHhgRkzPzrjoIdOKp+nhPZeZyqt8OXzrSoutG8g7gTzPz4foH/K+AU1umPQ18PDN/m5m/ycx1mXlFZm6s53+SqnF1crxJwFuAD2fm+sy8C/hf/O57BXB3Zv5tZm4GLqH63s0Y6WsDpgGPDln3KDB9K+OPAtPq78lItx06LpXMftbZ8cZLP1MbBriJY1+q0+db3F2vA1gKrAa+ExFrImIxQGauBt4D/A/ggYi4PCL2pTPrMnNTy/JGqh/SkdoTeD5wS0Q8EhGPAN+u12/xYGY+sWUhIp4fERfVN/A/BlwH7FI3s23ZA5jCs79XM1uW79/yJDM31k+357VtAHYasm4nqss77cZ3AjbU/zMa6bZDx6WS2c8mVj9TGwa4ieM+qlPwW7ygXkf9m9n7MvMA4A3AeyPimHrsssx8Vb1tUp3+76UcsvwQ1SWDgzJzl/qxc2ZOG2ab91H9dnxUZu4EzKvXx1bmDz3eUzz7e3XvCF5Dp26juvwDQETsSHWv2m3txuvnrWMHRMT0YcZb930A1dmHX3Sxfqkp9rOJ1c/UhgFu4vgq8NGI2LN+t9DHgK8ARMSJEfHi+lT2Y1SXGjZHxEsj4j9FxHOpbpL9TT3WS78CZkXEFIDMfBr4W+D8iNirrndmRLxumH1Mr2t9pP7TGR9vc4y2fyOpvozwdeCTETG9fhv8e6m/VyMVETtExFRgEjApIqa2vLPsm8DBEXFKPedjwKrM/Hk9vozqfz4z6zMF76O6uZrM/AVwK/Dxep9vonpn1xX1tpcCb4iIV9eN9C+AK4fcYyKVyn72zGOM936mNgxwE8cnqN7WvQr4CbCiXgcwB7iG6jT2D4C/ycwBqjM251L9Fnc/sBfVDcG99C9Uv3XdHxEP1es+RHVJ5Mb6EsI1DH//yWeA51HVfSPVJYpWnwXeHBG/jojPtdn+XcDjwBqqd2hdRpu3zXfoo1TNdzHw1vr5RwHqe3dOobqn5ddUNxO33gtzEfBPVP9ePwX+b71ui1OBufW25wJvrvdJZt5GdQP1pVTvnJsO/LftfA3SWGM/+51x38/UXlSXnyVJklQKz8BJkiQVxgAnSZJUGAOcJElSYQxwkiRJhTHASZIkFWaHbU8ZP/bYY4+cPXt202UA8Pjjj7Pjjjs2XcaIWXd/Wffo3XLLLQ9l5p7bnjm22b9Gz7r7y7pHb7j+NaEC3OzZs7n55pubLgOAgYEB5s+f33QZI2bd/WXdoxcRd2971thn/xo96+4v6x694fqXl1AlSZIKY4CTJEkqjAFOkiSpMBPqHjhponvqqacYHBzkiSee6Olxdt55Z26//faeHmOoqVOnMmvWLCZPntzX40rqn370sFL6lwFOmkAGBweZPn06s2fPJiJ6dpz169czffr0nu1/qMxk3bp1DA4Osv/++/ftuJL6qx89rJT+5SVUaQJ54okn2H333Xsa3poQEey+++49P7MoqVnjsYdtb/8ywEkTzHhqfK3G6+uS9Ezj8Wd9e16TAU5SX02bNq3pEiRpu42VHmaAkyRJKowBTlIjMpMPfOADHHzwwbzsZS/ja1/7GgBr165l3rx5HHrooRx88MFcf/31bN68mTPOOOM/5p5//vkNVy9pomu6h/kuVEmNuPLKK7n11ltZuXIlDz30EEcccQTz5s3jsssu43Wvex1Llixh8+bNbNy4kVtvvZV7772Xn/70pwA88sgjzRYvacJruocZ4KQJ6s//6TZ+dt9jXd3ngfvuxMffcFBHc2+44QZOO+00Jk2axIwZM3jNa17DTTfdxBFHHMFZZ53FU089xcknn8yhhx7KAQccwJo1a3jXu97F61//eo477riu1i2pPL3qYe+d/4KO5jbdw7yEKqkRmdl2/bx587juuuuYOXMmp59+OsuWLWPXXXdl5cqVzJ8/nwsuuIC3v/3tfa5Wkp6p6R7mGThpgur0TFmvzJs3j4suuoiFCxfy8MMPc91117F06VLuvvtuZs6cyTve8Q4ef/xxVqxYwYIFC5gyZQqnnHIKL3rRizjjjDMarV1S83rVw9avX9/RvKZ7mAFOUiPe9KY38YMf/IBDDjmEiOC8885j77335pJLLmHp0qVMnjyZadOmsWzZMu69917OPPNMnn76aQA+9alPNVy9pImu6R5mgJPUVxs2bACqP1y5dOlSli5d+ozxhQsXsnDhwmdtt2LFir7UJ0nDGSs9zHvgJEmSCmOAkyRJKowBTpIkqTAGOGmC2dpb30s3Xl+XpGcajz/r2/OaDHDSBDJ16lTWrVs37hpgZrJu3TqmTp3adCmSemg89rDt7V++C1WaQGbNmsXg4CAPPvhgT4/zxBNP9D1MTZ06lVmzZvX1mJL6qx89rJT+ZYCTJpDJkyez//779/w4AwMDHHbYYT0/jqSJpR89rJT+5SVUSZKkwhjgJEmSCmOAkyRJKowBTpIkqTAGOEmSpMIY4CRJkgpjgJMkSSqMAU6SJKkwjQa4iDg+Iu6IiNURsbjNeETE5+rxVRFx+JDxSRHx44j4Vv+qlqSKPUxSUxoLcBExCbgAOAE4EDgtIg4cMu0EYE79WAR8Ycj4u4Hbe1yqJD2LPUxSk5o8A3cksDoz12Tmk8DlwElD5pwELMvKjcAuEbEPQETMAl4P/F0/i5akmj1MUmOaDHAzgXtalgfrdZ3O+QzwQeDpHtUnScOxh0lqTJMfZh9t1mUncyLiROCBzLwlIuYPe5CIRVSXLpgxYwYDAwMjr7QHNmzYMGZqGQnr7i/rHtN63sPsX91l3f1l3b3VZIAbBPZrWZ4F3NfhnDcDb4yIBcBUYKeI+EpmvnXoQTLzYuBigLlz5+b8+fO79gJGY2BggLFSy0hYd39Z95jW8x5m/+ou6+4v6+6tJi+h3gTMiYj9I2IKcCpw1ZA5VwFvq9/JdTTwaGauzcwPZ+aszJxdb/cv7cKbJPWQPUxSYxo7A5eZmyLiHOBqYBLwpcy8LSLOrscvBJYDC4DVwEbgzKbqlaRW9jBJTWryEiqZuZyqwbWuu7DleQLv3MY+BoCBHpQnScOyh0lqip/EIEmSVBgDnCRJUmEMcJIkSYUxwEmSJBXGACdJklQYA5wkSVJhDHCSJEmFMcBJkiQVxgAnSZJUGAOcJElSYQxwkiRJhTHASZIkFcYAJ0mSVBgDnCRJUmEMcJIkSYUxwEmSJBXGACdJklQYA5wkSVJhDHCSJEmFMcBJkiQVxgAnSZJUGAOcJElSYQxwkiRJhTHASZIkFcYAJ0mSVBgDnCRJUmEMcJIkSYUxwEmSJBXGACdJklQYA5wkSVJhDHCSJEmFMcBJkiQVxgAnSZJUGAOcJElSYQxwkiRJhTHASZIkFcYAJ0mSVBgDnCRJUmEMcJIkSYUxwEmSJBXGACdJklSYRgNcRBwfEXdExOqIWNxmPCLic/X4qog4vF6/X0RcGxG3R8RtEfHu/lcvaaKzh0lqSmMBLiImARcAJwAHAqdFxIFDpp0AzKkfi4Av1Os3Ae/LzN8Hjgbe2WZbSeoZe5ikJjV5Bu5IYHVmrsnMJ4HLgZOGzDkJWJaVG4FdImKfzFybmSsAMnM9cDsws5/FS5rw7GGSGrNDg8eeCdzTsjwIHNXBnJnA2i0rImI2cBjww3YHiYhFVL/5MmPGDAYGBkZZdnds2LBhzNQyEtbdX9Y9pvW8h9m/usu6+8u6e6vJABdt1uVI5kTENOAK4D2Z+Vi7g2TmxcDFAHPnzs358+dvV7HdNjAwwFipZSSsu7+se0zreQ+zf3WXdfeXdfdWk5dQB4H9WpZnAfd1OiciJlM1vksz88oe1ilJ7djDJDWmyQB3EzAnIvaPiCnAqcBVQ+ZcBbytfifX0cCjmbk2IgL4InB7Zv7v/pYtSYA9TFKDGruEmpmbIuIc4GpgEvClzLwtIs6uxy8ElgMLgNXARuDMevNXAqcDP4mIW+t1H8nM5X18CZImMHuYpCY1eQ8cdbNaPmTdhS3PE3hnm+1uoP29JZLUN/YwSU3xkxgkSZIKY4CTJEkqjAFOkiSpMAY4SZKkwhjgJEmSCmOAkyRJKowBTpIkqTAGOEmSpMIY4CRJkgpjgJMkSSqMAU6SJKkwBjhJkqTCGOAkSZIKY4CTJEkqjAFOkiSpMAY4SZKkwhjgJEmSCmOAkyRJKowBTpIkqTAGOEmSpMIY4CRJkgpjgJMkSSqMAU6SJKkwBjhJkqTCGOAkSZIKY4CTJEkqjAFOkiSpMAY4SZKkwhjgJEmSCmOAkyRJKowBTpIkqTAGOEmSpMIY4CRJkgpjgJMkSSqMAU6SJKkwBjhJkqTCGOAkSZIK01GAi4h3R8ROUfliRKyIiON6XZwkdYM9TNJ40+kZuLMy8zHgOGBP4Ezg3J5VJUndZQ+TNK50GuCi/roA+PvMXNmyTpLGOnuYpHGl0wB3S0R8h6r5XR0R04GnR3vwiDg+Iu6IiNURsbjNeETE5+rxVRFxeKfbSlILe5ikcWWHDuf9MXAosCYzN0bEblSXILZbREwCLgBeCwwCN0XEVZn5s5ZpJwBz6sdRwBeAozrcVpK2sIdJGlc6PQP3CuCOzHwkIt4KfBR4dJTHPhJYnZlrMvNJ4HLgpCFzTgKWZeVGYJeI2KfDbSVpC3uYpHGl0wD3BWBjRBwCfBC4G1g2ymPPBO5pWR6s13Uyp5NtJWkLe5ikcaXTS6ibMjMj4iTgs5n5xYhYOMpjt7uBODuc08m21Q4iFgGLAGbMmMHAwMAISuydDRs2jJlaRsK6+8u6u6bIHmb/6i7r7i/r7q1OA9z6iPgwcDrw6vr+jcmjPPYgsF/L8izgvg7nTOlgWwAy82LgYoC5c+fm/PnzR1V0twwMDDBWahkJ6+4v6+6aInuY/au7rLu/rLu3Or2E+hbgt1R/S+l+qlP9S0d57JuAORGxf0RMAU4Frhoy5yrgbfU7uY4GHs3MtR1uK0lb2MMkjSsdnYHLzPsj4lLgiIg4EfhRZo7q/pHM3BQR5wBXA5OAL2XmbRFxdj1+IbCc6m3/q4GN1O8a29q2o6lH0vhlD5M03nQU4CLiv1D9tjpAde/GX0fEBzLzG6M5eGYup2pwresubHmewDs73VaS2rGHSRpvOr0HbglwRGY+ABARewLXAKNqfpLUJ/YwSeNKp/fAPWdL46utG8G2ktQ0e5ikcaXTM3Dfjoirga/Wy2/BU/+SymEPkzSudPomhg9ExCnAK6nuH7k4M7/Z08okqUvsYZLGm07PwJGZVwBX9LAWSeoZe5ik8WTYABcR62n/CQdB9QarnXpSlSR1wfTp0wEOi4jHhgzZwyQVbdgAl5nT+1WIJHXb+vXriYgfZ+bcpmuRpG7yXViSJEmFMcBJkiQVxgAnSZJUGAOcJElSYQxwkiRJhTHASZIkFcYAJ0mSVBgDnCRJUmEMcJIkSYUxwEmSJBXGACdJklQYA5wkSVJhDHCSJEmFMcBJkiQVxgAnSZJUGAOcJElSYQxwkiRJhTHASZIkFcYAJ0mSVBgDnCRJUmEMcJIkSYUxwEmSJBXGACdJklQYA5wkSVJhDHCSJEmFMcBJkiQVxgAnSZJUGAOcJElSYQxwkiRJhTHASZIkFcYAJ0mSVBgDnCRJUmEMcJIkSYUxwEmSJBWmkQAXEbtFxHcj4s76665bmXd8RNwREasjYnHL+qUR8fOIWBUR34yIXfpWvKQJzx4mqWlNnYFbDHwvM+cA36uXnyEiJgEXACcABwKnRcSB9fB3gYMz8w+AXwAf7kvVklSxh0lqVFMB7iTgkvr5JcDJbeYcCazOzDWZ+SRweb0dmfmdzNxUz7sRmNXbciXpGexhkhq1Q0PHnZGZawEyc21E7NVmzkzgnpblQeCoNvPOAr62tQNFxCJgEcCMGTMYGBjY3pq7asOGDWOmlpGw7v6y7jGrLz3M/tVd1t1f1t1bPQtwEXENsHeboSWd7qLNuhxyjCXAJuDSre0kMy8GLgaYO3duzp8/v8PD99bAwABjpZaRsO7+su7mjIUeZv/qLuvuL+vurZ4FuMw8dmtjEfGriNin/s11H+CBNtMGgf1almcB97XsYyFwInBMZiaS1EX2MEljWVP3wF0FLKyfLwT+sc2cm4A5EbF/REwBTq23IyKOBz4EvDEzN/ahXklqZQ+T1KimAty5wGsj4k7gtfUyEbFvRCwHqG/wPQe4Grgd+Hpm3lZv/3lgOvDdiLg1Ii7s9wuQNKHZwyQ1qpE3MWTmOuCYNuvvAxa0LC8HlreZ9+KeFihJw7CHSWqan8QgSZJUGAOcJElSYQxwkiRJhTHASZIkFcYAJ0mSVBgDnCRJUmEMcJIkSYUxwEmSJBXGACdJklQYA5wkSVJhDHCSJEmFMcBJkiQVxgAnSZJUGAOcJElSYQxwkiRJhTHASZIkFcYAJ0mSVBgDnCRJUmEMcJIkSYUxwEmSJBXGACdJklQYA5wkSVJhDHCSJEmFMcBJkiQVxgAnSZJUGAOcJElSYQxwkiRJhTHASZIkFcYAJ0mSVBgDnCRJUmEMcJIkSYUxwEmSJBXGACdJklQYA5wkSVJhDHCSJEmFMcBJkiQVxgAnSZJUGAOcJElSYQxwkiRJhTHASZIkFaaRABcRu0XEdyPizvrrrluZd3xE3BERqyNicZvx90dERsQeva9akir2MElNa+oM3GLge5k5B/hevfwMETEJuAA4ATgQOC0iDmwZ3w94LfDvfalYkn7HHiapUU0FuJOAS+rnlwAnt5lzJLA6M9dk5pPA5fV2W5wPfBDIHtYpSe3YwyQ1qqkANyMz1wLUX/dqM2cmcE/L8mC9joh4I3BvZq7sdaGS1IY9TFKjdujVjiPiGmDvNkNLOt1Fm3UZEc+v93Fch3UsAhYBzJgxg4GBgQ4P31sbNmwYM7WMhHX3l3U3Zyz0MPtXd1l3f1l3j2Vm3x/AHcA+9fN9gDvazHkFcHXL8ofrx8uAB4C76scmqntI9t7WcV/+8pfnWHHttdc2XcJ2se7+su7RA27OcdDD7F+jZ939Zd2jN1z/auoS6lXAwvr5QuAf28y5CZgTEftHxBTgVOCqzPxJZu6VmbMzczbVZYnDM/P+fhQuSdjDJDWsqQB3LvDaiLiT6l1Y5wJExL4RsRwgMzcB5wBXA7cDX8/M2xqqV5Ja2cMkNapn98ANJzPXAce0WX8fsKBleTmwfBv7mt3t+iRpOPYwSU3zkxgkSZIKY4CTJEkqjAFOkiSpMAY4SZKkwhjgJEmSCmOAkyRJKowBTpIkqTAGOEmSpMIY4CRJkgpjgJMkSSqMAU6SJKkwBjhJkqTCGOAkSZIKY4CTJEkqjAFOkiSpMAY4SZKkwhjgJEmSCmOAkyRJKowBTpIkqTAGOEmSpMIY4CRJkgpjgJMkSSqMAU6SJKkwBjhJkqTCGOAkSZIKY4CTJEkqjAFOkiSpMAY4SZKkwhjgJEmSCmOAkyRJKowBTpIkqTAGOEmSpMJEZjZdQ99ExIPA3U3XUdsDeKjpIraDdfeXdY/eCzNzz6aLGC37V1dYd39Z9+httX9NqAA3lkTEzZk5t+k6Rsq6+8u6NRaV+u9r3f1l3b3lJVRJkqTCGOAkSZIKY4BrzsVNF7CdrLu/rFtjUan/vtbdX9bdQ94DJ0mSVBjPwEmSJBXGANcjEbFbRHw3Iu6sv+66lXnHR8QdEbE6Iha3GX9/RGRE7NH7qkdfd0QsjYifR8SqiPhmROzS43q39f2LiPhcPb4qIg7vdNuxWHdE7BcR10bE7RFxW0S8u4S6W8YnRcSPI+Jb/ata28MeZg/rRd32sC7KTB89eADnAYvr54uBT7eZMwn4JXAAMAVYCRzYMr4fcDXV337ao4S6geOAHernn263fRdrHfb7V89ZAPwzEMDRwA873XaM1r0PcHj9fDrwixLqbhl/L3AZ8K1+1OxjVP/e9jB7WC/qtod16eEZuN45Cbikfn4JcHKbOUcCqzNzTWY+CVxeb7fF+cAHgX7eqDiqujPzO5m5qZ53IzCrh7Vu6/tHvbwsKzcCu0TEPh1uO+bqzsy1mbkCIDPXA7cDM8d63QARMQt4PfB3fapXo2MPs4d1vW57WPcY4HpnRmauBai/7tVmzkzgnpblwXodEfFG4N7MXNnrQocYVd1DnEX1m0yvdFLH1uZ0+hp6YTR1/4eImA0cBvyw+yW2Ndq6P0P1P/One1SfusseZg/bGnvYGLBD0wWULCKuAfZuM7Sk0120WZcR8fx6H8dtb23DHrRHdQ85xhJgE3DpyKobkW3WMcycTrbtldHUXQ1GTAOuAN6TmY91sbbhbHfdEXEi8EBm3hIR87tdmLaPPewZ7GGds4eNAQa4UcjMY7c2FhG/2nK6uD79+kCbaYNU94hsMQu4D3gRsD+wMiK2rF8REUdm5v1juO4t+1gInAgck/VNAz0ybB3bmDOlg217ZTR1ExGTqRrfpZl5ZQ/rHGo0db8ZeGNELACmAjtFxFcy8609rFfbYA97Vt1b9mEPG549bCz0sKZvwhuvD2Apz7yR9rw2c3YA1lA1ui03VB7UZt5d9O8G4FHVDRwP/AzYsw+1bvP7R3W/QusNqT8ayfd+DNYdwDLgMw38N73ddQ+ZM58xcAOwj23+e9vDel+rPay//02Pqx7W6MHH8wPYHfgecGf9dbd6/b7A8pZ5C6jehfNLYMlW9tXP5jequoHVVPcP3Fo/Luxxvc+qAzgbOLt+HsAF9fhPgLkj+d6PtbqBV1Gd8l/V8j1eMNbrHrKPMdH8fGzz39oeZg/ret32sO49/CQGSZKkwvguVEmSpMIY4CRJkgpjgJMkSSqMAU6SJKkwBjhJkqTCGOA0JkXE9+uvsyPiD7u874+0O5YkdYP9S/3gnxHRmFZ/ZMn7M/PEEWwzKTM3DzO+ITOndaE8Sdoq+5d6yTNwGpMiYkP99Fzg1RFxa0T8aURMioilEXFTRKyKiD+p58+PiGsj4jKqP75IRPxDRNwSEbdFxKJ63bnA8+r9Xdp6rKgsjYifRsRPIuItLfseiIhvRMTPI+LSqD8fSJKGsn+pH/wsVI11i2n5DbZuZI9m5hER8VzgXyPiO/XcI4GDM/Pf6uWzMvPhiHgecFNEXJGZiyPinMw8tM2x/jNwKHAIsEe9zXX12GHAQVSfifevwCuBG7r9YiWNK/Yv9Yxn4FSa44C3RcStwA+pPjZnTj32o5bmB/DfI2IlcCPVhxPPYXivAr6amZsz81fA/wOOaNn3YGY+TfXRL7O78FokTSz2L3WNZ+BUmgDelZlXP2Nlda/J40OWjwVekZkbI2IAmNrBvrfmty3PN+PPjqSRs3+pazwDp7FuPTC9Zflq4L9GxGSAiHhJROzYZrudgV/Xze/3gKNbxp7asv0Q1wFvqe9T2ROYB/yoK69C0kRk/1LPmMI11q0CNtWXEr4MfJbq9P+K+kbcB4GT22z3beDsiFgF3EF1GWKLi4FVEbEiM/+oZf03gVcAK4EEPpiZ99cNVJJGyv6lnvHPiEiSJBXGS6iSJEmFMcBJkiQVxgAnSZJUGAOcJElSYQxwkiRJhTHASZIkFcYAJ0mSVBgDnCRJUmH+P23162mIHrIqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "l = np.arange(len(train_loss_list))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(l, train_loss_list, label=\"loss\")\n",
    "plt.title(\"loss in iteration 10000\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(l[:1000], train_loss_list, label=\"loss\")\n",
    "plt.title(\"loss in iteration 1000\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1309e998",
   "metadata": {},
   "source": [
    "<img src=images/4_11.png height=700px width=700px>\n",
    "10000번으 실행한 결과와 1000번 실행된 결과를 확대한 이미지이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed6298",
   "metadata": {},
   "source": [
    "위의 이미지를 보면 학습 횟수가 늘어나면서 손실 함수의 값이 줄어든다. 이는 학습이 잘 되고 있다는 뜻으로, 신경망의 가중치 매개변수가 서서히 데이터에 적응하고 있음을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37255c73",
   "metadata": {},
   "source": [
    "# 4.5.3 시험 데이터로 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6723dc17",
   "metadata": {},
   "source": [
    "위의 손실 함수의 값이란, 정확히는 \"훈련 데이터의 미니배치의 대한 손실 함수\"의 값이다. 훈련 데이터의 손실 함수 값이 작아지는 것은 신경망이 잘 학습하고 있다는 방증이지만, 이 결과만으로는 다른 데이터셋에도 비슷한 실력을 발휘할지는 확실하지 않다.<br>\n",
    "신경망 학습에서는 \"__오버피팅__\"을 일으키지 않는지 확인해야 한다. 오버피팅 되었다는 것은 훈련 데이터에 포함된 이미지만 제대로 구분하고, 그렇지 않은 이미지는 식별할 수 없다는 뜻이다.<br>\n",
    "신경망 학습의 원래 목표는 범용적인 능력을 익히는 것이다. 범용 능력을 평가하려면 훈련 데이터에 포함되지 않은 데이터를 사용해 평가해 봐야한다. 이를 위해 다음 구현에서는 학습 도중 정기적으로 훈련 데이터와 시험 데이터를 대상으로 정확도를 기록한다. 여기에서는 1에폭(epoch)별로 훈련 데이터와 시험 데이터에 대한 정확도를 기록한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ea206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from source.dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# iteration number per 1 epoch\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "# hyper parameter\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    \n",
    "    # 기울기 계산\n",
    "    grd = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grd = network.gradient(x_batch, t_batch) => 성능 개선판\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in [\"W1\", \"W2\", \"b1\", \"b2\"]:\n",
    "        network.params[key] -= learning_rate * grd[key]\n",
    "        \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1epoch당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(f\"train acc, test acc | {train_acc}, {test acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc2791",
   "metadata": {},
   "source": [
    "앞선 코드로 얻은 결과를 그래프로 그려보면 다음과 같다.\n",
    "<img src=images/4_12.png height=700px, width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc8281",
   "metadata": {},
   "source": [
    "이 두 그래프가 거의 겹쳐져 있다는 뜻은, 오버피팅 없이 범용적인 가중치와 편향을 찾아내었다는 사실을 알려준다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
